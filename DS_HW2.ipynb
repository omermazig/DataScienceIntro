{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the HW grading is done in a semi-automatic manner, please adhere to the following naming format for your submission.\n",
    "Each group of students (mostly pairs, with some approved exceptions) should submit a Jupyter notebook (.ipynb file and not a .zip file) whose name is the underscored-separated id list of all the submitters. \n",
    "For example, for two submitters, the naming format is: id1_id2.ipynb."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"Boston1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (506, 16)\n",
      "Features: ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat', 'medv', 'randCol', 'misData']\n"
     ]
    }
   ],
   "source": [
    "# Exploring the data:\n",
    "print(\"Shape:\",df.shape)\n",
    "print(f\"Features: {df.columns.tolist()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Download the \"Boston1.csv\" database, and explore the data. Explanation about the dataset can be found here: http://www.clemson.edu/economics/faculty/wilson/R-tutorial/analyzing_data.html\n",
    "\n",
    "Find the columns with missing values and filter them out of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = df.dropna(axis=1) # droping columns with missing values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Divide the filtered data randomly into a train set (70% of the data) and test set (30% of the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(df,test_size=0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't done this previously, install the scikit-learn package for python.\n",
    "\n",
    "a) On the train set, run a linear regression model as follows:\n",
    "Divide the training set into explanatory variables (the X matrix with which we'll try to make a prediction) and a target variable (y, the value which we'll try to predict). Use the 'medv' attribute as the target variable y and the rest of the features as the X matrix. Run a linear regression model on those sets, and print the regression coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.89536546e-02,  5.89864781e-02,  1.02655350e-02,  2.68153325e+00,\n",
       "       -1.41618865e+01,  3.36849123e+00, -2.07096816e-03, -1.59933579e+00,\n",
       "        3.15579696e-01, -1.27807108e-02, -8.88464746e-01,  1.03431797e-02,\n",
       "       -6.28126757e-01,  9.50488916e-01])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "train_y = train_set[\"medv\"]\n",
    "train_X = train_set.drop(columns=[\"medv\"])\n",
    "model = LinearRegression()\n",
    "model.fit(train_X.values,train_y)\n",
    "model.coef_\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Use the linear regression model to predict the values of the test set's 'medv' column, based on the test set's other attributes. Print the Mean Squared Error of the model on the train set and on the test set.\n",
    "Usually, the MSE on the train set would be lower than the MSE on the test set, since the model parameters are optimized with respect to the train set. Must this always be the case? Can you think of a few examples for when this might not be the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE(Train set)=23.217880052825574\n",
      "MSE(Test set)=20.123314497718766\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "test_y = test_set[\"medv\"]\n",
    "test_X = test_set.drop(columns=[\"medv\"])\n",
    "prediction_on_test = model.predict(test_X.values)\n",
    "prediction_on_train = model.predict(train_X.values)\n",
    "    \n",
    "print(f\"MSE(Train set)={mse(prediction_on_train,train_y)}\")\n",
    "print(f\"MSE(Test set)={mse(prediction_on_test,test_y)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Is the MSE on the test set is always lower then MSE on the train set?</u> </br>\n",
    "It is possible that the train dataset's MSE is higher than the test dataset's MSE, since it's possible that the train data isn't realizable by linear regression - so it's not 0 - and by a chance, the test data only contains entries that fit exactly on the linear regression line. For example, see the code + outcome below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_set</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_set</td>\n",
       "      <td>1.720373e-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Set           MSE\n",
       "0  train_set  2.000000e+00\n",
       "1   test_set  1.720373e-28"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An un-realizable train data\n",
    "example_train_data = pd.DataFrame({'X': [1, 2, 3], 'Y': [1, 4, 1]})\n",
    "example_X_train = example_train_data.drop('Y', axis=1)\n",
    "example_y_train = example_train_data['Y']\n",
    "\n",
    "example_regression_model = LinearRegression()\n",
    "example_regression_model.fit(example_X_train, example_y_train)\n",
    "\n",
    "# A \"perfect\" test data\n",
    "example_test_data = pd.DataFrame({'X': range(100), 'Y': 100 * [2]})\n",
    "example_X_test = example_test_data.drop('Y', axis=1)\n",
    "example_y_test = example_test_data['Y']\n",
    "\n",
    "example_y_hat_train = example_regression_model.predict(example_X_train)\n",
    "example_train_MSE = mse(example_y_train, example_y_hat_train)\n",
    "\n",
    "example_y_hat_test = example_regression_model.predict(example_X_test)\n",
    "example_test_MSE = mse(example_y_test, example_y_hat_test)\n",
    "pd.DataFrame({'Set': ['train_set', 'test_set'], 'MSE': [example_train_MSE, example_test_MSE]})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Add some noise (with mean=0, std=1) to the test set's y, and predict it again. What happened to the MSE? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE(Noised test set) = 21.073748848012876\n"
     ]
    }
   ],
   "source": [
    "noise = np.random.normal(loc=0,scale=1,size=len(test_y.values))\n",
    "noised_test_y = test_y+noise\n",
    "print(f\"MSE(Noised test set) = {mse(prediction_on_test,noised_test_y)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE increased by a little bit.\n",
    "That's because we increased the distance from the linear model by increasing the desired output. The impact of the added noise on the MSE  is negligible becuase the std is somehow small compared to the std of the real disribution of the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Create a Recursive feature elimination model, with a linear regression estimator, that selects half of the original number of features. Hint: Check the feature_selection module in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Use the feature elimination model on the full database (after filtering columns with missing values, before partitioning into train/test). Print the features that were selected. Remember that we separate the 'medv' attribute to be our y, while the rest of the attributes in the dataset serve as features to learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chas', 'nox', 'rm', 'dis', 'ptratio', 'lstat', 'randCol']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=[\"medv\"])\n",
    "y = df[\"medv\"]\n",
    "rfe_model = rfe.fit(X.values,y)\n",
    "X.columns[rfe_model.get_support()].tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) We'd like to find out the optimal number of features. Create feature elimination models (with linear regression estimators) for every number of features between 1 and n (where n = all the original features, 'medv' excluded). For each number of features, run a linear regression as in Question 2, only on the selected features, in order to predict 'medv'. Print the Mean Sqaured Error for each number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for 1 selected features:  56.87282127976878\n",
      "MSE for 2 selected features:  30.982927152649093\n",
      "MSE for 3 selected features:  29.477808486186238\n",
      "MSE for 4 selected features:  23.44258183509568\n",
      "MSE for 5 selected features:  22.545306880080595\n",
      "MSE for 6 selected features:  20.733116007421653\n",
      "MSE for 7 selected features:  20.85411885972767\n",
      "MSE for 8 selected features:  21.187574013197235\n",
      "MSE for 9 selected features:  20.068925642197\n",
      "MSE for 10 selected features:  20.029387187011245\n",
      "MSE for 11 selected features:  20.70052181763582\n",
      "MSE for 12 selected features:  20.313665557276416\n",
      "MSE for 13 selected features:  20.11111979791632\n",
      "MSE for 14 selected features:  20.123314497718766\n"
     ]
    }
   ],
   "source": [
    "mse_i_list = list()\n",
    "features_number =  len(df.columns) -1\n",
    "for i in range(1,features_number+1):\n",
    "    rfe_i = RFE(model,n_features_to_select=i)\n",
    "    rfe_model = rfe_i.fit(X.values,y)\n",
    "    selected_features = train_X.columns[rfe_model.get_support()].tolist()\n",
    "    selected_X = train_X.reindex(columns = selected_features)\n",
    "    model.fit(selected_X.values,train_y) \n",
    "    selected_X_test = test_X.reindex(columns = selected_features)\n",
    "    mse_i = mse(model.predict(selected_X_test.values),test_y)\n",
    "    mse_i_list.append(mse_i)\n",
    "    print(\"MSE for\",i,\"selected features: \",mse_i)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Conclude the optimal number of features for this task. Think about the cost of adding for data vs the benefit of a more accurate prediction. Explain your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.scatter(range(1,features_number+1),mse_i_list)\n",
    "plt.xticks(range(1,features_number+1,1))\n",
    "plt.xlabel(\"number of features\")\n",
    "plt.ylabel(\"MSE\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the MSE achieved from 6 features isn't changing that much after adding more features. therefore 6 is the optimal number of features. </br>\n",
    "By eliminating irrelevant features, we cam improve the model's performance -  reduce overfitting, enhance interpretability, and speed up inference times."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a cross-validation of the linear regression on the train set with K=5. Print the CV scores for each repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77128718 0.74924982 0.55008553 0.57463221 0.75000391]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(cross_val_score(model, train_X, train_y, cv=5))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
